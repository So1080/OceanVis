import cv2
import numpy as np
import mediapipe as mp
import time

# === CONFIG ===
MAP_IMAGE_PATH = "map_reference.jpg"
CAMERA_INDEX = 1  # Change to 1 if your camera is at index 1

# === STEP 1: Load reference map image ===
ref_img = cv2.imread(MAP_IMAGE_PATH, cv2.IMREAD_GRAYSCALE)
if ref_img is None:
    print(f"Error: Could not load {MAP_IMAGE_PATH}")
    exit()

h_map, w_map = ref_img.shape

# === Initialize ORB ===
orb = cv2.ORB_create(1000)
kp1, des1 = orb.detectAndCompute(ref_img, None)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

# === Initialize camera ===
cap = cv2.VideoCapture(CAMERA_INDEX)
time.sleep(2)

print("[INFO] Finding map position in camera frame...")
success, frame = cap.read()
gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
kp2, des2 = orb.detectAndCompute(gray_frame, None)

matches = bf.match(des1, des2)
matches = sorted(matches, key=lambda x: x.distance)

# Filter matches (optional)
good_matches = matches[:50]

src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)
dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)

M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
if M is None:
    print("[ERROR] Could not find map in the camera view.")
    exit()

# Compute map corners in the camera frame
pts = np.float32([[0, 0], [0, h_map], [w_map, h_map], [w_map, 0]]).reshape(-1, 1, 2)
dst = cv2.perspectiveTransform(pts, M)
dst_int = np.int32(dst)

# Compute inverse homography for later point transform
inv_M = np.linalg.inv(M)

print("[INFO] Map detected and locked.")

# === Initialize MediaPipe Hands ===
mpHands = mp.solutions.hands
hands = mpHands.Hands(max_num_hands=1)
mpDraw = mp.solutions.drawing_utils

pTime = 0

while True:
    success, img = cap.read()
    if not success:
        break

    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(imgRGB)

    # Draw detected map area
    cv2.polylines(img, [dst_int], True, (255, 0, 0), 3)

    if results.multi_hand_landmarks:
        for handLms in results.multi_hand_landmarks:
            h_frame, w_frame, _ = img.shape

            for id, lm in enumerate(handLms.landmark):
                cx, cy = int(lm.x * w_frame), int(lm.y * h_frame)

                if id == 8:  # Index fingertip
                    cv2.circle(img, (cx, cy), 10, (0, 255, 0), cv2.FILLED)

                    # Check if fingertip is inside map polygon
                    inside = cv2.pointPolygonTest(dst, (cx, cy), False)

                    if inside >= 0:
                        # Convert fingertip to map coordinates
                        finger_point = np.array([[cx], [cy], [1]])
                        map_point = np.dot(inv_M, finger_point)
                        map_point /= map_point[2]

                        mx, my = map_point[0][0], map_point[1][0]

                        # Flip Y-axis: origin is bottom-left
                        relative_x = mx
                        relative_y = h_map - my

                        cv2.putText(img, f"In Map: ({int(relative_x)}, {int(relative_y)})",
                                    (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

                        print(f"[INFO] Finger relative to map: ({relative_x:.1f}, {relative_y:.1f})")

            mpDraw.draw_landmarks(img, handLms, mpHands.HAND_CONNECTIONS)

    # FPS display
    cTime = time.time()
    fps = 1 / (cTime - pTime) if cTime != pTime else 0
    pTime = cTime

    cv2.putText(img, f'FPS: {int(fps)}', (10, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2)

    cv2.imshow("Map Detection", img)
    if cv2.waitKey(1) & 0xFF == 27:  # ESC to quit
        break

cap.release()
cv2.destroyAllWindows()
